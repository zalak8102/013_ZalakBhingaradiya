{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrZevCPJ92HG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2769,
     "status": "ok",
     "timestamp": 1596080419533,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "1rmYBjsyCv3K",
    "outputId": "28ff5c05-155c-4639-f53c-c656d407ff0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data :\n",
      "        v1                                                 v2\n",
      "0    spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "1    spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "2    spam  WINNER!! As a valued network customer you have...\n",
      "3    spam  Had your mobile 11 months or more? U R entitle...\n",
      "4    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "..    ...                                                ...\n",
      "508  spam  This is the 2nd time we have tried 2 contact u...\n",
      "509   ham              Will �_ b going to esplanade fr home?\n",
      "510   ham  Pity, * was in mood for that. So...any other s...\n",
      "511   ham  The guy did some bitching but I acted like i'd...\n",
      "512   ham                         Rofl. Its true to its name\n",
      "\n",
      "[513 rows x 2 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 513 entries, 0 to 512\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      513 non-null    object\n",
      " 1   v2      513 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.1+ KB\n",
      "\n",
      "Data statistics\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "datasets = pd.read_csv('spam1.csv') \n",
    "print(\"\\nData :\\n\",datasets)\n",
    "print(\"\\nData statistics\\n\",datasets.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkvmsbgkNRe4"
   },
   "source": [
    "##Analysis\n",
    "\n",
    "To analyze the text data, we have to turn the words into numerical numbers. \n",
    "We have multiple choices to accomplish this step: \n",
    "\n",
    "1) Binary Term Frequency :  count presence(1) or absence(0) for term in document\n",
    "\n",
    "2) Bag of Words Frequency:  captures the frequency of term in document\n",
    "\n",
    "3) Term Frequency: \n",
    "\n",
    "4) TFIDF :\n",
    "\n",
    "in this way, if a term appears frequently in a document, it’s important; if a term appears in many documents, it’s not a unique identifier.\n",
    "\n",
    "Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TbhXzh5ONQ5R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFDvCoaVbEUV"
   },
   "source": [
    "#Next we use CountVectorizer:\n",
    "\n",
    "More Details and example at:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9LhzBBgSC3S5"
   },
   "outputs": [],
   "source": [
    "#MINOR CORRECTION IN LAB'S CODE:\n",
    "\n",
    "#BY MISTAKE WE HAVE APPLIED \"FIT_TRANSFORM\" TO TEST DATA ALSO INSTEAD OF ONLY \"TRANSFORM\"\n",
    "#AND WHENEVER WE HAVE CORRECTED IT, THE XTRAIN,XTEST WAS ALREADY MODIFIED\n",
    "#SO, SIMPLE RERUN YOUR TRAIN_TEST_SPLIT CODE AND NEXT IF YOU TRY WITH THE GIVEN CODE, IT WILL WORK\n",
    "\n",
    "#Hope You got the Point !!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9vB3hKHIEFr"
   },
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NcC9U7_DHw03"
   },
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZAmSYVKIWG5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYu4_PnbIxfw"
   },
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oqjGef-FIw7U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3i5VpsczbgsS"
   },
   "source": [
    "**Optional Exercise:**\n",
    "Try this on full spam.csv file and bigram matching instead of unigram matching "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SpamText-NB and DT.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
